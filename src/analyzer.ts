/**
 * æ€§èƒ½åˆ†æå·¥å…·
 * 
 * æä¾›æ·±å…¥çš„æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®
 */
import { performance, PerformanceObserver } from 'node:perf_hooks'

export interface PerformanceAnalysis {
  /** å†…å­˜ä½¿ç”¨æƒ…å†µ */
  memory: {
    used: number
    total: number
    percentage: number
  }

  /** CPU ä½¿ç”¨æƒ…å†µ */
  cpu: {
    user: number
    system: number
  }

  /** æ‰§è¡Œæ—¶é—´åˆ†æ */
  timing: {
    total: number
    setup: number
    execution: number
    teardown: number
  }

  /** æ€§èƒ½ç“¶é¢ˆ */
  bottlenecks: PerformanceBottleneck[]

  /** ä¼˜åŒ–å»ºè®® */
  recommendations: string[]
}

export interface PerformanceBottleneck {
  /** ç“¶é¢ˆç±»å‹ */
  type: 'memory' | 'cpu' | 'io' | 'gc' | 'event-loop'

  /** ä¸¥é‡ç¨‹åº¦ */
  severity: 'low' | 'medium' | 'high' | 'critical'

  /** æè¿° */
  description: string

  /** å½±å“çš„ä»»åŠ¡ */
  affectedTasks: string[]

  /** å»ºè®®çš„è§£å†³æ–¹æ¡ˆ */
  solution: string
}

export class PerformanceAnalyzer {
  private measurements: Map<string, any> = new Map()
  private observer?: PerformanceObserver

  /**
   * å¼€å§‹æ€§èƒ½åˆ†æ
   */
  startAnalysis(taskName: string): void {
    const startMemory = process.memoryUsage()
    const startCpu = process.cpuUsage()
    const startTime = performance.now()

    this.measurements.set(taskName, {
      startMemory,
      startCpu,
      startTime,
      marks: []
    })

    // è®¾ç½®æ€§èƒ½è§‚å¯Ÿå™¨
    this.setupPerformanceObserver(taskName)
  }

  /**
   * ç»“æŸæ€§èƒ½åˆ†æ
   */
  endAnalysis(taskName: string): PerformanceAnalysis {
    const measurement = this.measurements.get(taskName)
    if (!measurement) {
      throw new Error(`æœªæ‰¾åˆ°ä»»åŠ¡ ${taskName} çš„æ€§èƒ½æµ‹é‡æ•°æ®`)
    }

    const endMemory = process.memoryUsage()
    const endCpu = process.cpuUsage(measurement.startCpu)
    const endTime = performance.now()

    // æ¸…ç†è§‚å¯Ÿå™¨
    this.cleanupPerformanceObserver()

    const memoryUsed = endMemory.heapUsed - measurement.startMemory.heapUsed
    const memoryTotal = endMemory.heapTotal
    const memoryPercentage = (memoryUsed / memoryTotal) * 100

    const totalTime = endTime - measurement.startTime

    const analysis: PerformanceAnalysis = {
      memory: {
        used: memoryUsed,
        total: memoryTotal,
        percentage: memoryPercentage
      },
      cpu: {
        user: endCpu.user / 1000, // è½¬æ¢ä¸ºæ¯«ç§’
        system: endCpu.system / 1000
      },
      timing: {
        total: totalTime,
        setup: 0, // éœ€è¦å®é™…æµ‹é‡
        execution: totalTime,
        teardown: 0 // éœ€è¦å®é™…æµ‹é‡
      },
      bottlenecks: this.identifyBottlenecks(taskName, measurement, {
        memoryUsed,
        memoryPercentage,
        cpuUsage: endCpu,
        totalTime
      }),
      recommendations: this.generateRecommendations(taskName, {
        memoryUsed,
        memoryPercentage,
        cpuUsage: endCpu,
        totalTime
      })
    }

    return analysis
  }

  /**
   * æ·»åŠ æ€§èƒ½æ ‡è®°
   */
  mark(taskName: string, markName: string): void {
    const measurement = this.measurements.get(taskName)
    if (measurement) {
      measurement.marks.push({
        name: markName,
        time: performance.now()
      })
    }
  }

  /**
   * è®¾ç½®æ€§èƒ½è§‚å¯Ÿå™¨
   */
  private setupPerformanceObserver(taskName: string): void {
    this.observer = new PerformanceObserver((list) => {
      const entries = list.getEntries()
      entries.forEach(entry => {
        if (entry.entryType === 'measure') {
          this.mark(taskName, `measure:${entry.name}`)
        } else if (entry.entryType === 'mark') {
          this.mark(taskName, `mark:${entry.name}`)
        }
      })
    })

    this.observer.observe({ entryTypes: ['measure', 'mark'] })
  }

  /**
   * æ¸…ç†æ€§èƒ½è§‚å¯Ÿå™¨
   */
  private cleanupPerformanceObserver(): void {
    if (this.observer) {
      this.observer.disconnect()
      this.observer = undefined
    }
  }

  /**
   * è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
   */
  private identifyBottlenecks(
    taskName: string,
    _measurement: any,
    metrics: any
  ): PerformanceBottleneck[] {
    const bottlenecks: PerformanceBottleneck[] = []

    // å†…å­˜ç“¶é¢ˆæ£€æµ‹
    if (metrics.memoryUsed > 100 * 1024 * 1024) { // 100MB
      bottlenecks.push({
        type: 'memory',
        severity: 'high',
        description: 'å†…å­˜ä½¿ç”¨é‡è¿‡é«˜',
        affectedTasks: [taskName],
        solution: 'è€ƒè™‘ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œé¿å…å†…å­˜æ³„æ¼ï¼Œä½¿ç”¨å¯¹è±¡æ± ç­‰æŠ€æœ¯'
      })
    } else if (metrics.memoryPercentage > 80) {
      bottlenecks.push({
        type: 'memory',
        severity: 'medium',
        description: 'å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜',
        affectedTasks: [taskName],
        solution: 'ç›‘æ§å†…å­˜ä½¿ç”¨ï¼Œè€ƒè™‘å†…å­˜ä¼˜åŒ–'
      })
    }

    // CPU ç“¶é¢ˆæ£€æµ‹
    const totalCpu = metrics.cpuUsage.user + metrics.cpuUsage.system
    if (totalCpu > 1000) { // 1ç§’ CPU æ—¶é—´
      bottlenecks.push({
        type: 'cpu',
        severity: 'high',
        description: 'CPU ä½¿ç”¨æ—¶é—´è¿‡é•¿',
        affectedTasks: [taskName],
        solution: 'ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦ï¼Œè€ƒè™‘ä½¿ç”¨ Worker çº¿ç¨‹åˆ†æ‹…è®¡ç®—'
      })
    }

    // æ‰§è¡Œæ—¶é—´ç“¶é¢ˆ
    if (metrics.totalTime > 5000) { // 5ç§’
      bottlenecks.push({
        type: 'event-loop',
        severity: 'critical',
        description: 'æ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œå¯èƒ½é˜»å¡äº‹ä»¶å¾ªç¯',
        affectedTasks: [taskName],
        solution: 'å°†é•¿ä»»åŠ¡æ‹†åˆ†ä¸ºå°å—ï¼Œä½¿ç”¨å¼‚æ­¥å¤„ç†ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯'
      })
    } else if (metrics.totalTime > 1000) { // 1ç§’
      bottlenecks.push({
        type: 'event-loop',
        severity: 'medium',
        description: 'æ‰§è¡Œæ—¶é—´è¾ƒé•¿',
        affectedTasks: [taskName],
        solution: 'è€ƒè™‘ä¼˜åŒ–æ‰§è¡Œæ•ˆç‡'
      })
    }

    return bottlenecks
  }

  /**
   * ç”Ÿæˆä¼˜åŒ–å»ºè®®
   */
  private generateRecommendations(
    taskName: string,
    metrics: any
  ): string[] {
    const recommendations: string[] = []

    // å†…å­˜ä¼˜åŒ–å»ºè®®
    if (metrics.memoryUsed > 50 * 1024 * 1024) {
      recommendations.push(
        `ä»»åŠ¡ "${taskName}" å†…å­˜ä½¿ç”¨è¾ƒé«˜ (${this.formatBytes(metrics.memoryUsed)})ï¼Œå»ºè®®ï¼š` +
        `\n  â€¢ æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼` +
        `\n  â€¢ ä½¿ç”¨å¯¹è±¡æ± å¤ç”¨å¯¹è±¡` +
        `\n  â€¢ åŠæ—¶é‡Šæ”¾ä¸å†ä½¿ç”¨çš„å¼•ç”¨`
      )
    }

    // CPU ä¼˜åŒ–å»ºè®®
    const totalCpu = metrics.cpuUsage.user + metrics.cpuUsage.system
    if (totalCpu > 500) {
      recommendations.push(
        `ä»»åŠ¡ "${taskName}" CPU ä½¿ç”¨è¾ƒé«˜ (${totalCpu.toFixed(2)}ms)ï¼Œå»ºè®®ï¼š` +
        `\n  â€¢ ä¼˜åŒ–ç®—æ³•æ—¶é—´å¤æ‚åº¦` +
        `\n  â€¢ ä½¿ç”¨ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—` +
        `\n  â€¢ è€ƒè™‘ä½¿ç”¨ Worker çº¿ç¨‹`
      )
    }

    // æ‰§è¡Œæ—¶é—´ä¼˜åŒ–å»ºè®®
    if (metrics.totalTime > 1000) {
      recommendations.push(
        `ä»»åŠ¡ "${taskName}" æ‰§è¡Œæ—¶é—´è¾ƒé•¿ (${metrics.totalTime.toFixed(2)}ms)ï¼Œå»ºè®®ï¼š` +
        `\n  â€¢ åˆ†ææ€§èƒ½çƒ­ç‚¹è¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–` +
        `\n  â€¢ ä½¿ç”¨æ€§èƒ½åˆ†æå·¥å…·å®šä½ç“¶é¢ˆ` +
        `\n  â€¢ è€ƒè™‘å¼‚æ­¥å¤„ç†æˆ–åˆ†æ‰¹æ‰§è¡Œ`
      )
    }

    // å¦‚æœæ²¡æœ‰æ˜æ˜¾é—®é¢˜ï¼Œç»™å‡ºä¸€èˆ¬æ€§å»ºè®®
    if (recommendations.length === 0) {
      recommendations.push(
        `ä»»åŠ¡ "${taskName}" æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå¯ä»¥å…³æ³¨ï¼š` +
        `\n  â€¢ æŒç»­ç›‘æ§æ€§èƒ½å˜åŒ–` +
        `\n  â€¢ å®šæœŸè¿›è¡Œæ€§èƒ½æµ‹è¯•` +
        `\n  â€¢ å…³æ³¨å†…å­˜ä½¿ç”¨è¶‹åŠ¿`
      )
    }

    return recommendations
  }

  /**
   * æ ¼å¼åŒ–å­—èŠ‚å¤§å°
   */
  private formatBytes(bytes: number): string {
    const units = ['B', 'KB', 'MB', 'GB']
    let size = bytes
    let unitIndex = 0

    while (size >= 1024 && unitIndex < units.length - 1) {
      size /= 1024
      unitIndex++
    }

    return `${size.toFixed(2)} ${units[unitIndex]}`
  }

  /**
   * ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
   */
  generateReport(analysis: PerformanceAnalysis, taskName: string): string {
    let report = `# æ€§èƒ½åˆ†ææŠ¥å‘Š: ${taskName}

## ğŸ“Š æ€§èƒ½æ¦‚è§ˆ

### å†…å­˜ä½¿ç”¨
- ä½¿ç”¨å†…å­˜: ${this.formatBytes(analysis.memory.used)}
- æ€»å†…å­˜: ${this.formatBytes(analysis.memory.total)}
- ä½¿ç”¨ç‡: ${analysis.memory.percentage.toFixed(2)}%

### CPU ä½¿ç”¨
- ç”¨æˆ·æ—¶é—´: ${analysis.cpu.user.toFixed(2)}ms
- ç³»ç»Ÿæ—¶é—´: ${analysis.cpu.system.toFixed(2)}ms

### æ‰§è¡Œæ—¶é—´
- æ€»æ—¶é—´: ${analysis.timing.total.toFixed(2)}ms
- æ‰§è¡Œæ—¶é—´: ${analysis.timing.execution.toFixed(2)}ms

`

    // ç“¶é¢ˆåˆ†æ
    if (analysis.bottlenecks.length > 0) {
      report += `## ğŸš¨ æ€§èƒ½ç“¶é¢ˆ\n\n`
      analysis.bottlenecks.forEach(bottleneck => {
        const severityIcon = {
          low: 'ğŸ”µ',
          medium: 'ğŸŸ¡',
          high: 'ğŸŸ ',
          critical: 'ğŸ”´'
        }[bottleneck.severity]

        report += `${severityIcon} **${bottleneck.type.toUpperCase()} ç“¶é¢ˆ** (${bottleneck.severity})\n`
        report += `- æè¿°: ${bottleneck.description}\n`
        report += `- å½±å“: ${bottleneck.affectedTasks.join(', ')}\n`
        report += `- å»ºè®®: ${bottleneck.solution}\n\n`
      })
    } else {
      report += `## âœ… æ— æ˜¾è‘—æ€§èƒ½ç“¶é¢ˆ\n\n`
    }

    // ä¼˜åŒ–å»ºè®®
    report += `## ğŸ’¡ ä¼˜åŒ–å»ºè®®\n\n`
    analysis.recommendations.forEach(rec => {
      report += `${rec}\n\n`
    })

    return report
  }

  /**
   * æ¯”è¾ƒå¤šä¸ªåˆ†æç»“æœ
   */
  compareAnalyses(analyses: Map<string, PerformanceAnalysis>): string {
    let comparison = `# æ€§èƒ½åˆ†æå¯¹æ¯”æŠ¥å‘Š\n\n`

    const tasks = Array.from(analyses.keys())

    comparison += `## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”\n\n`
    comparison += `| ä»»åŠ¡ | å†…å­˜ä½¿ç”¨ | CPU æ—¶é—´ | æ‰§è¡Œæ—¶é—´ | ç“¶é¢ˆæ•°é‡ |\n`
    comparison += `|------|----------|----------|----------|----------|\n`

    tasks.forEach(taskName => {
      const analysis = analyses.get(taskName)!
      comparison += `| ${taskName} `
      comparison += `| ${this.formatBytes(analysis.memory.used)} `
      comparison += `| ${(analysis.cpu.user + analysis.cpu.system).toFixed(2)}ms `
      comparison += `| ${analysis.timing.total.toFixed(2)}ms `
      comparison += `| ${analysis.bottlenecks.length} |\n`
    })

    // æ‰¾å‡ºæ€§èƒ½æœ€å·®çš„ä»»åŠ¡
    const worstTask = tasks.reduce((worst, current) => {
      const currentAnalysis = analyses.get(current)!
      const worstAnalysis = analyses.get(worst)!

      const currentScore = currentAnalysis.timing.total +
        currentAnalysis.memory.used / (1024 * 1024) +
        (currentAnalysis.cpu.user + currentAnalysis.cpu.system)

      const worstScore = worstAnalysis.timing.total +
        worstAnalysis.memory.used / (1024 * 1024) +
        (worstAnalysis.cpu.user + worstAnalysis.cpu.system)

      return currentScore > worstScore ? current : worst
    }, tasks[0])

    comparison += `\n## ğŸ¯ é‡ç‚¹å…³æ³¨\n\n`
    comparison += `**æ€§èƒ½æœ€å·®çš„ä»»åŠ¡**: ${worstTask}\n`
    comparison += `**å»ºè®®**: ä¼˜å…ˆä¼˜åŒ–æ­¤ä»»åŠ¡çš„æ€§èƒ½ç“¶é¢ˆ\n`

    return comparison
  }
}

/**
 * åˆ›å»ºæ€§èƒ½åˆ†æå™¨å®ä¾‹
 */
export function createPerformanceAnalyzer(): PerformanceAnalyzer {
  return new PerformanceAnalyzer()
}
